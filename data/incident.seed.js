// data/incident.seed.js
export const incidentData = [
  {
    title: 'AI model recommended biased hiring criteria',
    description:
      'An AI system used in hiring recommended biased criteria based on gender, leading to unequal job offers.',
    severity: 'High',
    reported_at: '2025-04-18T10:30:00.000Z',
  },
  {
    title: 'Self-driving car misinterpreted stop sign',
    description:
      "The self-driving car's AI system failed to detect a stop sign and caused a near-collision.",
    severity: 'High',
    reported_at: '2025-04-16T14:00:00.000Z',
  },
  {
    title: 'AI chatbot failed to identify mental health crisis',
    description:
      'A mental health AI chatbot misinterpreted distress signals and provided inadequate advice.',
    severity: 'High',
    reported_at: '2025-04-14T09:15:00.000Z',
  },
  {
    title: 'Facial recognition system misidentified suspect',
    description:
      'A facial recognition AI system falsely identified an innocent person as a criminal, leading to wrongful accusations.',
    severity: 'Medium',
    reported_at: '2025-04-12T16:45:00.000Z',
  },
  {
    title: 'AI model predicted an incorrect stock trend',
    description:
      'The AI-powered stock market prediction model failed to predict a major market crash, leading to significant financial losses.',
    severity: 'Medium',
    reported_at: '2025-04-10T11:00:00.000Z',
  },
  {
    title: 'AI language model generated offensive content',
    description:
      'An AI language model generated offensive and inappropriate content during a live chat with users.',
    severity: 'High',
    reported_at: '2025-04-08T18:20:00.000Z',
  },
  {
    title: 'AI assistant recommended harmful health advice',
    description:
      'An AI-powered health assistant recommended harmful health practices based on faulty data analysis.',
    severity: 'High',
    reported_at: '2025-04-06T13:25:00.000Z',
  },
  {
    title: 'AI system mismanaged user data',
    description:
      'An AI system handling personal data leaked sensitive user information due to a security vulnerability.',
    severity: 'High',
    reported_at: '2025-04-04T17:35:00.000Z',
  },
  {
    title: 'AI model used in predictive policing caused racial bias',
    description:
      'An AI system used for predictive policing overrepresented minority communities in crime predictions, leading to discrimination.',
    severity: 'Medium',
    reported_at: '2025-04-02T08:45:00.000Z',
  },
  {
    title: 'AI-powered drone malfunctioned during delivery',
    description:
      'An AI-powered drone malfunctioned and crashed during a delivery, causing damage to property.',
    severity: 'Low',
    reported_at: '2025-03-31T12:50:00.000Z',
  },
];
